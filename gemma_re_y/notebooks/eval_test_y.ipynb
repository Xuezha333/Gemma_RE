{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/gemma/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "login('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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Define the checkpoint directory\n",
    "checkpoint_path = \"/root/autodl-tmp/Projects/Gemma_RE/gemma_re_y/notebooks/Xuezha333/gemma-qlora-re_2024-04-06_13-18-00/checkpoint-400\"  # Replace with your checkpoint path\n",
    "\n",
    "# Load the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint_path,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             device_map=\"cuda:0\"\n",
    "                                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002765655517578125\n",
      "### Question: he is the author of eight books which have charted the transformation of europe over the last quarter-century .\n",
      " ### Answer: {'head': 'author', 'tail': 'books', 'relation': 'Product-Producer(e1,e2)'}\n"
     ]
    }
   ],
   "source": [
    "question = \"patriarch cerularius eventually wrote a tract against the western liturgical practices .\"\n",
    "formatted_prompt = f\"### Question: {question}\\n ### Answer:\"\n",
    "input_ids = tokenizer.encode(formatted_prompt, return_tensors='pt').to(device)\n",
    "s = time.time()\n",
    "t = time.time()\n",
    "print(t-s)\n",
    "outputs = model.generate(input_ids, max_length=120, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "s = time.time()\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "t = time.time()\n",
    "print(t-s)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{\"prompt\": \"patriarch cerularius eventually wrote a tract against the western liturgical practices .\", \"completion\": {\"h\": \"tract\", \"hpos\": \"(5, 6)\", \"t\": \"liturgical practices\", \"tpos\": \"(9, 11)\", \"relation\": 7}}\n",
    "{\"prompt\": \"gatrell illuminates the debate over public execution that raged in polite society .\", \"completion\": {\"h\": \"debate\", \"hpos\": \"(3, 4)\", \"t\": \"public execution\", \"tpos\": \"(5, 7)\", \"relation\": 7}}\n",
    "{\"prompt\": \"you have been asked to make notes about a telephone call left by a colleague in the german office of the bank .\", \"completion\": {\"h\": \"notes\", \"hpos\": \"(6, 7)\", \"t\": \"telephone call\", \"tpos\": \"(9, 11)\", \"relation\": 7}}\n",
    "{\"prompt\": \"questions on various aspects of the study were raised and discussed .\", \"completion\": {\"h\": \"questions\", \"hpos\": \"(0, 1)\", \"t\": \"aspects\", \"tpos\": \"(3, 4)\", \"relation\": 7}}\n",
    "{\"prompt\": \"he is the author of eight books which have charted the transformation of europe over the last quarter-century .\", \"completion\": {\"h\": \"books\", \"hpos\": \"(6, 7)\", \"t\": \"transformation\", \"tpos\": \"(11, 12)\", \"relation\": 7}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yz's eval starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test file\n",
    "# or all test data in a list\n",
    "import json\n",
    "with open('data/yr_test_file.json', 'r') as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "from tqdm import trange\n",
    "test_predict = []\n",
    "for i in trange(len(test_data)):\n",
    "    time.sleep(0.1)\n",
    "    response, history = model.chat(tokenizer, test_data[i], history=[])\n",
    "    test_predict.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predict file\n",
    "with open('data/yr_predict_file.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(test_predict, file, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = ['{\"token\": [\"the\", \"most\", \"common\", \"audits\", \"were\", \"about\", \"waste\", \"and\", \"recycling\", \".\"], \"h\": {\"name\": \"audits\", \"pos\": [3, 4]}, \"t\": {\"name\": \"waste\", \"pos\": [6, 7]}, \"relation\": \"Message-Topic(e1,e2)\"}',\n",
    "'{\"token\": [\"this\", \"thesis\", \"defines\", \"the\", \"clinical\", \"characteristics\", \"of\", \"amyloid\", \"disease\", \".\"], \"h\": {\"name\": \"thesis\", \"pos\": [1, 2]}, \"t\": {\"name\": \"clinical characteristics\", \"pos\": [4, 6]}, \"relation\": \"Message-Topic(e1,e2)\"}',\n",
    "'{\"token\": [\"this\", \"outline\", \"focuses\", \"on\", \"spirituality\", \",\", \"esotericism\", \",\", \"mysticism\", \",\", \"religion\", \"and/or\", \"parapsychology\", \".\"], \"h\": {\"name\": \"outline\", \"pos\": [1, 2]}, \"t\": {\"name\": \"spirituality\", \"pos\": [4, 5]}, \"relation\": \"Message-Topic(e1,e2)\"}',\n",
    "'{\"token\": [\"many\", \"of\", \"his\", \"literary\", \"pieces\", \"narrate\", \"and\", \"mention\", \"stories\", \"that\", \"took\", \"place\", \"in\", \"lipa\", \".\"], \"h\": {\"name\": \"pieces\", \"pos\": [4, 5]}, \"t\": {\"name\": \"stories\", \"pos\": [8, 9]}, \"relation\": \"Other\"}',\n",
    "'{\"token\": [\"news\", \"programs\", \"commented\", \"on\", \"the\", \"violence\", \"from\", \"the\", \"game\", \"and\", \"expressed\", \"worries\", \"on\", \"how\", \"it\", \"would\", \"affect\", \"the\", \"players\", \"\\'\", \"personalities\", \".\"], \"h\": {\"name\": \"news programs\", \"pos\": [0, 2]}, \"t\": {\"name\": \"violence\", \"pos\": [5, 6]}, \"relation\": \"Message-Topic(e1,e2)\"}',\n",
    "'{\"token\": [\"in\", \"the\", \"article\", \",\", \"the\", \"authors\", \"explore\", \"the\", \"use\", \"of\", \"technology\", \"in\", \"small\", \"pharmacy\", \"chains\", \".\"], \"h\": {\"name\": \"article\", \"pos\": [2, 3]}, \"t\": {\"name\": \"use\", \"pos\": [8, 9]}, \"relation\": \"Message-Topic(e1,e2)\"}',\n",
    "'{\"token\": [\"the\", \"magazine\", \"was\", \"founded\", \"in\", \"order\", \"to\", \"keep\", \"athletes\", \"serving\", \"as\", \"soldiers\", \"informed\", \"about\", \"their\", \"sport\", \"back\", \"home\", \".\"], \"h\": {\"name\": \"magazine\", \"pos\": [1, 2]}, \"t\": {\"name\": \"sport\", \"pos\": [15, 16]}, \"relation\": \"Other\"}']\n",
    "\n",
    "test_predict = ['{\"token\": [\"the\", \"most\", \"common\", \"audits\", \"were\", \"about\", \"waste\", \"and\", \"recycling\", \".\"], \"h\": {\"name\": \"audits\", \"pos\": [3, 4]}, \"t\": {\"name\": \"waste\", \"pos\": [6, 7]}, \"relation\": \"Message-Topic(e1,e2)\"}',\n",
    "'{\"token\": [\"this\", \"thesis\", \"defines\", \"the\", \"clinical\", \"characteristics\", \"of\", \"amyloid\", \"disease\", \".\"], \"h\": {\"name\": \"the\", \"pos\": [1, 2]}, \"t\": {\"name\": \"clinical characteristics\", \"pos\": [4, 6]}, \"relation\": \"Message-Topic(e1,e2)\"}',\n",
    "'{\"token\": [\"this\", \"outline\", \"focuses\", \"on\", \"spirituality\", \",\", \"esotericism\", \",\", \"mysticism\", \",\", \"religion\", \"and/or\", \"parapsychology\", \".\"], \"h\": {\"name\": \"outline\", \"pos\": [1, 2]}, \"t\": {\"name\": \"spirituality\", \"pos\": [4, 5]}, \"relation\": \"Message-Topic(e1,e2)\"}',\n",
    "'{\"token\": [\"many\", \"of\", \"his\", \"literary\", \"pieces\", \"narrate\", \"and\", \"mention\", \"stories\", \"that\", \"took\", \"place\", \"in\", \"lipa\", \".\"], \"h\": {\"name\": \"pieces\", \"pos\": [4, 5]}, \"t\": {\"name\": \"stories\", \"pos\": [8, 9]}, \"relation\": \"Message-Topic(e1,e2)\"}',\n",
    "'{\"token\": [\"news\", \"programs\", \"commented\", \"on\", \"the\", \"violence\", \"from\", \"the\", \"game\", \"and\", \"expressed\", \"worries\", \"on\", \"how\", \"it\", \"would\", \"affect\", \"the\", \"players\", \"\\'\", \"personalities\", \".\"], \"h\": {\"name\": \"news programs\", \"pos\": [0, 2]}, \"t\": {\"name\": \"violence\", \"pos\": [5, 6]}, \"relation\": \"Other\"}',\n",
    "'{\"token\": [\"in\", \"the\", \"article\", \",\", \"the\", \"authors\", \"explore\", \"the\", \"use\", \"of\", \"technology\", \"in\", \"small\", \"pharmacy\", \"chains\", \".\"], \"h\": {\"name\": \"article\", \"pos\": [2, 3]}, \"t\": {\"name\": \"use\", \"pos\": [8, 9]}, \"relation\": \"Other\"}',\n",
    "'{\"token\": [\"the\", \"magazine\", \"was\", \"founded\", \"in\", \"order\", \"to\", \"keep\", \"athletes\", \"serving\", \"as\", \"soldiers\", \"informed\", \"about\", \"their\", \"sport\", \"back\", \"home\", \".\"], \"h\": {\"name\": \"magazine\", \"pos\": [1, 2]}, \"t\": {\"name\": \"sport\", \"pos\": [15, 16]}, \"relation\": \"Other\"}']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "data = pd.DataFrame({'ans':test_data,'predict':test_predict})\n",
    "data = data.applymap(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ans</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'token': ['the', 'most', 'common', 'audits', ...</td>\n",
       "      <td>{'token': ['the', 'most', 'common', 'audits', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'token': ['this', 'thesis', 'defines', 'the',...</td>\n",
       "      <td>{'token': ['this', 'thesis', 'defines', 'the',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'token': ['this', 'outline', 'focuses', 'on',...</td>\n",
       "      <td>{'token': ['this', 'outline', 'focuses', 'on',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'token': ['many', 'of', 'his', 'literary', 'p...</td>\n",
       "      <td>{'token': ['many', 'of', 'his', 'literary', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'token': ['news', 'programs', 'commented', 'o...</td>\n",
       "      <td>{'token': ['news', 'programs', 'commented', 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'token': ['in', 'the', 'article', ',', 'the',...</td>\n",
       "      <td>{'token': ['in', 'the', 'article', ',', 'the',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'token': ['the', 'magazine', 'was', 'founded'...</td>\n",
       "      <td>{'token': ['the', 'magazine', 'was', 'founded'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ans  \\\n",
       "0  {'token': ['the', 'most', 'common', 'audits', ...   \n",
       "1  {'token': ['this', 'thesis', 'defines', 'the',...   \n",
       "2  {'token': ['this', 'outline', 'focuses', 'on',...   \n",
       "3  {'token': ['many', 'of', 'his', 'literary', 'p...   \n",
       "4  {'token': ['news', 'programs', 'commented', 'o...   \n",
       "5  {'token': ['in', 'the', 'article', ',', 'the',...   \n",
       "6  {'token': ['the', 'magazine', 'was', 'founded'...   \n",
       "\n",
       "                                             predict  \n",
       "0  {'token': ['the', 'most', 'common', 'audits', ...  \n",
       "1  {'token': ['this', 'thesis', 'defines', 'the',...  \n",
       "2  {'token': ['this', 'outline', 'focuses', 'on',...  \n",
       "3  {'token': ['many', 'of', 'his', 'literary', 'p...  \n",
       "4  {'token': ['news', 'programs', 'commented', 'o...  \n",
       "5  {'token': ['in', 'the', 'article', ',', 'the',...  \n",
       "6  {'token': ['the', 'magazine', 'was', 'founded'...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  ans predict\n",
      "0   0       0\n",
      "1   0       1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "1\n",
      "  ans predict\n",
      "2   1       0\n",
      "3   1       1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "2\n",
      "  ans predict\n",
      "4   2       1\n",
      "5   2       1\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "  ans predict\n",
      "0   0       0\n",
      "1   0       1\n",
      "2   1       0\n",
      "3   1       1\n",
      "4   2       1\n",
      "5   2       1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "'''d = pd.DataFrame({'ans':['0','0','1','1','2','2'],'predict':['0','1','0','1','1','1']})\n",
    "d = d.groupby('ans')\n",
    "groups = pd.DataFrame({'ans':[],'predict':[]})\n",
    "for name,group in d:\n",
    "    print(name)\n",
    "    print(group)\n",
    "    print(type(group))\n",
    "    groups = pd.concat([groups, group])\n",
    "print(groups)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(groups[groups['ans']=='1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ans</th>\n",
       "      <th>predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ans predict\n",
       "3   1       1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groups[(groups['ans']=='1') & (groups['predict']=='1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ans</th>\n",
       "      <th>predict</th>\n",
       "      <th>a_relation</th>\n",
       "      <th>p_relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'token': ['the', 'most', 'common', 'audits', ...</td>\n",
       "      <td>{'token': ['the', 'most', 'common', 'audits', ...</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'token': ['this', 'thesis', 'defines', 'the',...</td>\n",
       "      <td>{'token': ['this', 'thesis', 'defines', 'the',...</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'token': ['this', 'outline', 'focuses', 'on',...</td>\n",
       "      <td>{'token': ['this', 'outline', 'focuses', 'on',...</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'token': ['many', 'of', 'his', 'literary', 'p...</td>\n",
       "      <td>{'token': ['many', 'of', 'his', 'literary', 'p...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'token': ['news', 'programs', 'commented', 'o...</td>\n",
       "      <td>{'token': ['news', 'programs', 'commented', 'o...</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'token': ['in', 'the', 'article', ',', 'the',...</td>\n",
       "      <td>{'token': ['in', 'the', 'article', ',', 'the',...</td>\n",
       "      <td>Message-Topic(e1,e2)</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'token': ['the', 'magazine', 'was', 'founded'...</td>\n",
       "      <td>{'token': ['the', 'magazine', 'was', 'founded'...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 ans  \\\n",
       "0  {'token': ['the', 'most', 'common', 'audits', ...   \n",
       "1  {'token': ['this', 'thesis', 'defines', 'the',...   \n",
       "2  {'token': ['this', 'outline', 'focuses', 'on',...   \n",
       "3  {'token': ['many', 'of', 'his', 'literary', 'p...   \n",
       "4  {'token': ['news', 'programs', 'commented', 'o...   \n",
       "5  {'token': ['in', 'the', 'article', ',', 'the',...   \n",
       "6  {'token': ['the', 'magazine', 'was', 'founded'...   \n",
       "\n",
       "                                             predict            a_relation  \\\n",
       "0  {'token': ['the', 'most', 'common', 'audits', ...  Message-Topic(e1,e2)   \n",
       "1  {'token': ['this', 'thesis', 'defines', 'the',...  Message-Topic(e1,e2)   \n",
       "2  {'token': ['this', 'outline', 'focuses', 'on',...  Message-Topic(e1,e2)   \n",
       "3  {'token': ['many', 'of', 'his', 'literary', 'p...                 Other   \n",
       "4  {'token': ['news', 'programs', 'commented', 'o...  Message-Topic(e1,e2)   \n",
       "5  {'token': ['in', 'the', 'article', ',', 'the',...  Message-Topic(e1,e2)   \n",
       "6  {'token': ['the', 'magazine', 'was', 'founded'...                 Other   \n",
       "\n",
       "             p_relation  \n",
       "0  Message-Topic(e1,e2)  \n",
       "1  Message-Topic(e1,e2)  \n",
       "2  Message-Topic(e1,e2)  \n",
       "3  Message-Topic(e1,e2)  \n",
       "4                 Other  \n",
       "5                 Other  \n",
       "6                 Other  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_relation = []\n",
    "p_relation = []\n",
    "for i in range(len(data)):\n",
    "    a_relation.append(data['ans'][i]['relation'])\n",
    "    p_relation.append(data['predict'][i]['relation'])\n",
    "data['a_relation'] = a_relation\n",
    "data['p_relation'] = p_relation\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all kind of relation extraction\n",
    "'''rlt = [\"Component-Whole(e2,e1)\",\n",
    "    \"Other\",\n",
    "    \"Instrument-Agency(e2,e1)\",\n",
    "    \"Member-Collection(e1,e2)\",\n",
    "    \"Cause-Effect(e2,e1)\",\n",
    "    \"Entity-Destination(e1,e2)\",\n",
    "    \"Content-Container(e1,e2)\",\n",
    "    \"Message-Topic(e1,e2)\",\n",
    "    \"Product-Producer(e2,e1)\",\n",
    "    \"Member-Collection(e2,e1)\",\n",
    "    \"Entity-Origin(e1,e2)\",\n",
    "    \"Cause-Effect(e1,e2)\",\n",
    "    \"Component-Whole(e1,e2)\",\n",
    "    \"Message-Topic(e2,e1)\",\n",
    "    \"Product-Producer(e1,e2)\",\n",
    "    \"Entity-Origin(e2,e1)\",\n",
    "    \"Content-Container(e2,e1)\",\n",
    "    \"Instrument-Agency(e1,e2)\",\n",
    "    \"Entity-Destination(e2,e1)\"]'''\n",
    "rlt = ['Other','Message-Topic(e1,e2)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 在xxx关系的eval中：\n",
    "correct_by_relation表示：预测结果显示有关系，实际标签也是有关系，并且两个的结果是吻合的，进行计数（TP）；\n",
    "\n",
    "guessed_by_relation表示：预测显示有关系则全部进行计数（TP+FP）；\n",
    "\n",
    "gold_by_relation：实际标签显示有关系则全部进行计数（TP+FN）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'audits', 'pos': [3, 4]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ans = data['ans'][0]\n",
    "ans['h']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token': ['the', 'magazine', 'was', 'founded', 'in', 'order', 'to', 'keep', 'athletes', 'serving', 'as', 'soldiers', 'informed', 'about', 'their', 'sport', 'back', 'home', '.'], 'h': {'name': 'magazine', 'pos': [1, 2]}, 't': {'name': 'sport', 'pos': [15, 16]}, 'relation': 'Other'} {'token': ['the', 'magazine', 'was', 'founded', 'in', 'order', 'to', 'keep', 'athletes', 'serving', 'as', 'soldiers', 'informed', 'about', 'their', 'sport', 'back', 'home', '.'], 'h': {'name': 'magazine', 'pos': [1, 2]}, 't': {'name': 'sport', 'pos': [15, 16]}, 'relation': 'Other'}\n",
      "0\n",
      "magazine magazine\n",
      "sport sport\n",
      "{'token': ['the', 'most', 'common', 'audits', 'were', 'about', 'waste', 'and', 'recycling', '.'], 'h': {'name': 'audits', 'pos': [3, 4]}, 't': {'name': 'waste', 'pos': [6, 7]}, 'relation': 'Message-Topic(e1,e2)'} {'token': ['the', 'most', 'common', 'audits', 'were', 'about', 'waste', 'and', 'recycling', '.'], 'h': {'name': 'audits', 'pos': [3, 4]}, 't': {'name': 'waste', 'pos': [6, 7]}, 'relation': 'Message-Topic(e1,e2)'}\n",
      "0\n",
      "audits audits\n",
      "waste waste\n",
      "{'token': ['this', 'thesis', 'defines', 'the', 'clinical', 'characteristics', 'of', 'amyloid', 'disease', '.'], 'h': {'name': 'thesis', 'pos': [1, 2]}, 't': {'name': 'clinical characteristics', 'pos': [4, 6]}, 'relation': 'Message-Topic(e1,e2)'} {'token': ['this', 'thesis', 'defines', 'the', 'clinical', 'characteristics', 'of', 'amyloid', 'disease', '.'], 'h': {'name': 'the', 'pos': [1, 2]}, 't': {'name': 'clinical characteristics', 'pos': [4, 6]}, 'relation': 'Message-Topic(e1,e2)'}\n",
      "{'token': ['this', 'outline', 'focuses', 'on', 'spirituality', ',', 'esotericism', ',', 'mysticism', ',', 'religion', 'and/or', 'parapsychology', '.'], 'h': {'name': 'outline', 'pos': [1, 2]}, 't': {'name': 'spirituality', 'pos': [4, 5]}, 'relation': 'Message-Topic(e1,e2)'} {'token': ['this', 'outline', 'focuses', 'on', 'spirituality', ',', 'esotericism', ',', 'mysticism', ',', 'religion', 'and/or', 'parapsychology', '.'], 'h': {'name': 'outline', 'pos': [1, 2]}, 't': {'name': 'spirituality', 'pos': [4, 5]}, 'relation': 'Message-Topic(e1,e2)'}\n",
      "2\n",
      "outline outline\n",
      "spirituality spirituality\n",
      "{'Other': [1, 3, 2], 'Message-Topic(e1,e2)': [2, 4, 5]}\n"
     ]
    }
   ],
   "source": [
    "# TP, TP+FP, TP+TN\n",
    "result = dict()\n",
    "#r = \"Message-Topic(e1,e2)\"\n",
    "for r in rlt:\n",
    "    correct_by_relation = 0\n",
    "    guessed_by_relation = len(data[data['p_relation']==r])\n",
    "    gold_by_relation = len(data[data['a_relation']==r])\n",
    "    df = data[(data['p_relation']==r) & (data['a_relation']==r)].reset_index(drop=True)\n",
    "    #print(df)\n",
    "    for i in range(len(df)):\n",
    "        ans = df['ans'][i]\n",
    "        predict = df['predict'][i]\n",
    "        print(ans, predict)\n",
    "        #print(i)\n",
    "        if ans['h']['name']==predict['h']['name'] and ans['t']['name']==predict['t']['name']:\n",
    "            print(i)\n",
    "            print(ans['h']['name'],predict['h']['name'])\n",
    "            print(ans['t']['name'],predict['t']['name'])\n",
    "            correct_by_relation += 1\n",
    "    result[r] = [correct_by_relation, guessed_by_relation, gold_by_relation] # TP, TP+FP, TP+TN\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Other': [0.33, 0.5, 0.4], 'Message-Topic(e1,e2)': [0.5, 0.4, 0.44]}\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "evaluation = dict()\n",
    "for k in result:\n",
    "    precision = round(result[k][0]/result[k][1],2)\n",
    "    recall = round(result[k][0]/result[k][2],2)\n",
    "    f1 = round((2*precision*recall)/(precision+recall),2)\n",
    "    evaluation[k] = [precision, recall, f1] #p, r, f1\n",
    "\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_macro: 0.42\n",
      "r_macro: 0.45\n",
      "f1_macro: 0.42\n"
     ]
    }
   ],
   "source": [
    "# macro p, r, f1\n",
    "p_macro_lst = [value[0] for value in evaluation.values()]\n",
    "p_macro = round(sum(p_macro_lst)/len(p_macro_lst),2)\n",
    "r_macro_lst = [value[1] for value in evaluation.values()]\n",
    "r_macro = round(sum(r_macro_lst)/len(r_macro_lst),2)\n",
    "f1_macro_lst = [value[2] for value in evaluation.values()]\n",
    "f1_macro = round(sum(f1_macro_lst)/len(f1_macro_lst),2)\n",
    "print('p_macro: ' + str(p_macro))\n",
    "print('r_macro: ' + str(r_macro))\n",
    "print('f1_macro: ' + str(f1_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_micro: 0.43\n",
      "r_micro: 0.43\n",
      "f1_micro: 0.43\n"
     ]
    }
   ],
   "source": [
    "# micro p, r, f1\n",
    "TP_lst = [value[0] for value in result.values()]\n",
    "TPFP_lst = [value[1] for value in result.values()]\n",
    "TPTN_lst = [value[2] for value in result.values()]\n",
    "p_micro = round(sum(TP_lst)/sum(TPFP_lst),2)\n",
    "r_micro = round(sum(TP_lst)/sum(TPTN_lst),2)\n",
    "f1_micro = round((2*p_micro*r_micro)/(p_micro+r_micro),2)\n",
    "print('p_micro: ' + str(p_micro))\n",
    "print('r_micro: ' + str(r_micro))\n",
    "print('f1_micro: ' + str(f1_micro))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
